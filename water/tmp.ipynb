{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import bokeh.plotting\n",
    "import catboost\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import sklearn.preprocessing, sklearn.feature_selection, sklearn.model_selection\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "import sklearn.base\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import seaborn as sns\n",
    "import dateutil.parser\n",
    "import collections\n",
    "import sklearn.utils\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed = SEED\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport numpy as np\n",
    "\n",
    "cpdef float qtof_(x):\n",
    "    qtys = {\n",
    "        'enough': 1.0,\n",
    "        'insufficient': .6,\n",
    "        'seasonal': .4,\n",
    "        'dry': .2,\n",
    "        'unknown': 0,\n",
    "    }\n",
    "    if x in qtys:\n",
    "        return qtys[x]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabelencodeAll:\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        self.encs_ = collections.defaultdict(sklearn.preprocessing.LabelEncoder)\n",
    "    def fit(self, X, y=None):\n",
    "        for c in self.cols:\n",
    "            if c not in X.columns: continue\n",
    "            if not np.issubdtype(X[c].dtype, np.number):\n",
    "                self.encs_[c].fit(X[c])\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c, enc in self.encs_.items():\n",
    "            if c not in X.columns: continue\n",
    "            if not c in X.columns: continue\n",
    "            if not np.issubdtype(X.loc[:,c].dtype, np.number):\n",
    "                X.loc[:,c] = enc.transform(X.loc[:,c])\n",
    "        return X\n",
    "\n",
    "class DecodeQuantity(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col):\n",
    "        self.col = col\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X.loc[:,self.col] = X.loc[:,self.col].map(qtof_)\n",
    "        return X\n",
    "    \n",
    "    \n",
    "class HideMissingValues(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in X.columns:\n",
    "            if np.issubdtype(X.loc[:,c].dtype, np.number):\n",
    "                med = X.loc[:,c].median()\n",
    "                if np.isnan(med):\n",
    "                    med = 0\n",
    "                X.loc[:,c].fillna(med, inplace=True)\n",
    "            elif set(X.loc[:,c].unique()).issubset({True, False, np.nan}):\n",
    "                X.loc[X.loc[:,c] == 1, c] = 1\n",
    "                X.loc[X.loc[:,c] != 1, c] = 0\n",
    "                X.loc[:,c].fillna(0.5, inplace=True)\n",
    "            else:\n",
    "                X.loc[:,c].fillna('unknown', inplace=True)\n",
    "                X.loc[:,c] = X.loc[:,c].astype('str')\n",
    "        return X\n",
    "    \n",
    "\n",
    "class DropGarbage(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=['id', 'funder', 'recorded_by', 'date_recorded']):\n",
    "        self.cols = cols\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.drop(self.cols, axis=1, errors='ignore')\n",
    "\n",
    "class SplitDate(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col, drop=True):\n",
    "        self.col = col\n",
    "        self.drop = drop\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        def t(x):\n",
    "            if isinstance(x, str):\n",
    "                try:\n",
    "                    x = dateutil.parser.parse(x)\n",
    "                except:\n",
    "                    return (np.nan, np.nan, np.nan, np.nan)\n",
    "            elif pd.isnull(x):\n",
    "                return (np.nan, np.nan, np.nan, np.nan)\n",
    "            return (x.year, x.month, x.day, x.weekday())\n",
    "        X = X.copy()\n",
    "        (X.loc[:, self.col + '_year'],\n",
    "         X.loc[:, self.col + '_month'],\n",
    "         X.loc[:, self.col + '_day'],\n",
    "         X.loc[:, self.col + '_weekday']) = zip(\n",
    "        *X.loc[:, self.col].map(t))\n",
    "        if self.drop:\n",
    "            X.drop(self.col, axis=1, inplace=True)\n",
    "        return X\n",
    "\n",
    "    \n",
    "class HandyFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X.loc[:,'amount_per_man'] = X.loc[:,'amount_tsh']/X.loc[:,'population']\n",
    "        return X\n",
    "\n",
    "class OutcomeFrequences(BaseException, TransformerMixin):\n",
    "    def __init__(self, groupby, drop=False):\n",
    "        self.groupby = groupby\n",
    "        self.drop = drop\n",
    "        self.cnts_ = None\n",
    "        self.fq_cols_ = None\n",
    "        self.unknowns_ = 0\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        possible_outcomes = [_.split()[-1] if isinstance(_, str) else _ for _ in np.unique(y)]\n",
    "        n_outs = len(possible_outcomes)\n",
    "        self.cnts_ = collections.defaultdict(lambda: np.zeros(n_outs))\n",
    "        # print(self.groupby)\n",
    "        igroupby = np.array([X.columns.get_loc(_) for _ in self.groupby])\n",
    "        for i in range(X.shape[0]):\n",
    "            # assuming $y$ is label-encoded\n",
    "            keys, out = tuple(X.iloc[i, igroupby].values), y[i]\n",
    "            self.cnts_[keys][out] += 1 # no of `(keys, out)` occurences\n",
    "        for k in self.cnts_:\n",
    "            self.cnts_[k] //= self.cnts_[k].sum()\n",
    "            \n",
    "        self.possible_outcomes_ = possible_outcomes\n",
    "        self.fq_cols_ = ['_'.join(self.groupby + [str(out), 'fq'],) for out in possible_outcomes]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        self.unknowns_ = 0\n",
    "        igroupby = np.array([X.columns.get_loc(_) for _ in self.groupby])\n",
    "        new_cols = [tuple([None for out in self.possible_outcomes_]) for _ in range(X.shape[0])]\n",
    "        for i in range(X.shape[0]):\n",
    "            keys = tuple(X.iloc[i, igroupby].values)\n",
    "            if keys in self.cnts_:\n",
    "                new_cols[i] = tuple([self.cnts_[keys][out] for out in self.possible_outcomes_])\n",
    "            else:\n",
    "                self.unknowns_ += 1\n",
    "        self.unknowns_ /= X.size\n",
    "        # print(str(X)[:100])\n",
    "        # print(str(new_cols)[:100])\n",
    "        # print(str(self.fq_cols_[:100]))\n",
    "        new_cols = pd.DataFrame(new_cols, columns=self.fq_cols_)\n",
    "        for c in self.fq_cols_:\n",
    "            new_cols.loc[:,c].fillna(0, inplace=True) # new_cols.loc[:,c].median(), inplace=True)\n",
    "        X = pd.concat((X, new_cols,), axis=1)\n",
    "        if self.drop:\n",
    "            X.drop(self.groupby, axis=1, inplace=True, errors='ignore')\n",
    "        return X\n",
    "\n",
    "class ExplicitAge(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X.loc[:, 'age'] = X.loc[:,'date_recorded_year'] - X.loc[:,'construction_year']\n",
    "        return X\n",
    "\n",
    "def show_intersections(A, B, add_cat_feats=['date_recorded', 'construction_year',\n",
    "                                            'date_recorded_year', 'date_recorded_month']):\n",
    "    cat_features = np.where(np.array([(X_train[c].dtype == object)\n",
    "                                  or (c.endswith('code'))\n",
    "                                  or (c in add_cat_feats) for c in X_train.columns.values]))[0]\n",
    "    cat_feats_observed = []\n",
    "    for c in cat_features:\n",
    "        n_uni = len(set(A.iloc[:,c]).union(B.iloc[:,c]))\n",
    "        n_int = len(set(A.iloc[:,c]).intersection(B.iloc[:,c]))\n",
    "        n_te = len(set(A.iloc[:,c]))\n",
    "        cat_feats_observed.append((A.columns[c], n_int/n_uni, n_int/n_te))\n",
    "    cat_feats_observed = (\n",
    "        pd.DataFrame(cat_feats_observed, columns=['var', 'intersection/union', 'intersection/B'])\n",
    "        .sort_values('intersection/B')\n",
    "    )\n",
    "    return cat_feats_observed\n",
    "\n",
    "        \n",
    "def split_train_cv_test(X, y, proportions=(.75, .25/2, .25/2)):\n",
    "    # expecting $y$ to be numpy array\n",
    "    outs = np.unique(y)\n",
    "    proportions = np.array(proportions)\n",
    "    classes = [np.where(y == i)[0] for i in outs]\n",
    "    xparts = [[] for _ in proportions]\n",
    "    yparts = [[] for _ in proportions]\n",
    "    for cidx in classes:\n",
    "        cidx = sklearn.utils.shuffle(cidx)\n",
    "        cprops = cidx.size * proportions\n",
    "        cprops = cprops.astype(int)\n",
    "        cprops[-1] = cidx.size - cprops[:-1].sum()\n",
    "        # print(cidx)\n",
    "        cx = X.iloc[cidx,:]\n",
    "        cy = y[cidx]\n",
    "        for xpart, ypart, sz in zip(xparts, yparts, cprops):\n",
    "            xpart.append(cx.iloc[:sz,:])\n",
    "            ypart.append(cy[:sz])\n",
    "            cx, cy = cx.iloc[sz:,:], cy[sz:]\n",
    "    xparts = [pd.concat(xpart) for xpart in xparts]\n",
    "    yparts = [np.concatenate(ypart) for ypart in yparts]\n",
    "    parts = xparts + yparts\n",
    "    return parts\n",
    "def cat_features_indices(X):\n",
    "    return np.where(np.array([(X[c].dtype == object)\n",
    "        or (c.endswith('code'))                                                  \n",
    "    for c in X.columns.values]))[0]\n",
    "\n",
    "def cat_features_names(X):\n",
    "    return X.columns[cat_features_indices(X)]\n",
    "\n",
    "def copy_and_reset(X, cols, cat_unknown='unknown', num_unknown=0):\n",
    "    X = X.copy()\n",
    "    for c in cols:\n",
    "        if ((X[c].dtype == object)\n",
    "            or (c.endswith('code'))\n",
    "            or ('date' in c and '_fq' not in c)):\n",
    "            X.loc[:,c] = cat_unknown\n",
    "        else:\n",
    "            X.loc[:,c] = num_unknown\n",
    "    return X\n",
    "\n",
    "def spawn_noisy(X, y, colsets_to_noise):\n",
    "    X = X.drop('id', axis=1, errors='ignore').copy()\n",
    "    X = pd.concat([copy_and_reset(X, cols).reset_index(drop=True)\n",
    "                  for cols in colsets_to_noise],\n",
    "                 ignore_index=True)\n",
    "    y = np.concatenate([y\n",
    "                  for cols in colsets_to_noise])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 40)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(59400, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(14850, 40)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = pd.read_csv('X_train.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "show_intersections(X_train, X_test)\n",
    "display(X_train.shape, y_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'amount_tsh', 'date_recorded', 'funder', 'gps_height',\n",
       "       'installer', 'longitude', 'latitude', 'wpt_name', 'num_private',\n",
       "       'basin', 'subvillage', 'region', 'region_code', 'district_code', 'lga',\n",
       "       'ward', 'population', 'public_meeting', 'recorded_by',\n",
       "       'scheme_management', 'scheme_name', 'permit', 'construction_year',\n",
       "       'extraction_type', 'extraction_type_group', 'extraction_type_class',\n",
       "       'management', 'management_group', 'payment', 'payment_type',\n",
       "       'water_quality', 'quality_group', 'quantity', 'quantity_group',\n",
       "       'source', 'source_type', 'source_class', 'waterpoint_type',\n",
       "       'waterpoint_type_group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PrefitedPipeline:\n",
    "    def __init__(self, steps, verbose=1):\n",
    "        self.steps = steps\n",
    "        self.verbose = verbose\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if self.verbose > 2:\n",
    "            print('Input columns: %s' % X.columns)\n",
    "        for stepname, step in self.steps:\n",
    "            if self.verbose > 0:\n",
    "                print('Executing %s' % stepname)\n",
    "            X = step.transform(X)\n",
    "            if self.verbose > 2:\n",
    "                print('Step %s output columns: %s' % (stepname,\n",
    "                                                      X.columns if isinstance(X, pd.DataFrame)\n",
    "                                                      else type(X)))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_enc = sklearn.preprocessing.LabelEncoder()\n",
    "y_tr = y_enc.fit_transform(y_train.iloc[:,1])\n",
    "xtr, xcv, xva, ytr, ycv, yva = split_train_cv_test(X_train, y_tr, proportions=(.7, .15, .15))\n",
    "xtr, ytr = spawn_noisy(xtr, ytr, cols_to_reset)\n",
    "prepr0.fit(xtr.append(), ytr)\n",
    "\n",
    "\n",
    "cols_to_reset = [\n",
    "    [],\n",
    "    ['wpt_name'],\n",
    "    ['wpt_name', 'installer', 'funder'],\n",
    "    ['wpt_name', 'subvillage'],\n",
    "    ['wpt_name', 'subvillage'],\n",
    "    ['wpt_name', 'subvillage', 'installer', 'funder' ],\n",
    "    ['wpt_name', 'subvillage', 'installer', 'funder', 'scheme_name',\n",
    "     'ward', 'region_code', ],\n",
    "    ['wpt_name', 'subvillage', 'installer', 'funder', 'scheme_management',\n",
    "     'ward', 'region_code', 'date_recorded'],\n",
    "    ['funder', 'gps_height',\n",
    "       'installer', 'longitude', 'latitude', 'wpt_name', 'num_private',\n",
    "       'basin', 'subvillage', 'region', 'region_code', 'district_code', 'lga',\n",
    "       'ward', 'public_meeting', 'recorded_by', 'scheme_name', 'payment', 'payment_type',],\n",
    "    ['amount_tsh', 'funder', 'installer', 'date_recorded', 'construction_year',\n",
    "     'longitude', 'latitude', 'wpt_name', 'num_private',\n",
    "       'subvillage', 'region_code', 'district_code',\n",
    "       'ward', 'population', 'public_meeting', 'recorded_by',\n",
    "       'scheme_name', 'extraction_type', 'management', 'management_group',\n",
    "     'payment', 'payment_type',],\n",
    "    ['funder', 'installer', 'wpt_name', 'num_private',\n",
    "       'subvillage', 'region_code', 'district_code', \n",
    "       'public_meeting', 'recorded_by',\n",
    "      'payment', 'payment_type',],\n",
    "    ['funder', 'gps_height',\n",
    "       'installer', 'longitude', 'latitude', 'wpt_name', 'num_private',\n",
    "       'basin', 'subvillage', 'region',\n",
    "       'ward', 'public_meeting', 'recorded_by',\n",
    "     'scheme_name', 'payment', 'payment_type',],\n",
    "    ['funder', 'installer', 'wpt_name', 'num_private',\n",
    "       'subvillage', 'region_code', 'district_code', \n",
    "       'public_meeting', 'recorded_by',\n",
    "      'payment', 'payment_type',],\n",
    "    ['funder', 'installer', 'wpt_name', 'num_private',\n",
    "       'subvillage', 'region_code', 'district_code', \n",
    "       'public_meeting', 'recorded_by',\n",
    "      'payment', 'payment_type',],\n",
    "]\n",
    "# Step 1, preprocessing\n",
    "prepr0 = PrefitedPipeline([\n",
    "    ('qty', DecodeQuantity('quantity')),\n",
    "    ('date_recorded', SplitDate('date_recorded', drop=True)),\n",
    "    ('age', ExplicitAge()),\n",
    "    ('fillna', HideMissingValues()),\n",
    "    ('handyfeats', HandyFeatures()),\n",
    "    ('fillna2', HideMissingValues()),\n",
    "    ('labelenc', LabelencodeAll(cols=cat_features_names(X_train))),\n",
    "] + [\n",
    "    (catcol + '_fq', OutcomeFrequences([catcol], drop=False))\n",
    "    for catcol in ['installer', 'subvillage', 'region', 'basin','date_recorded_month',\n",
    "                   'extraction_type_class',]\n",
    "] + [\n",
    "    ('drop', DropGarbage(cols=[\n",
    "        'id', 'recorded_by', 'num_private', 'date_recorded_year', 'date_recorded_day'\n",
    "    ]))\n",
    "])\n",
    "xtr = prepr0.transform(xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sizes: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=582092, step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "59400"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('sizes: ', xtr.index, y_tr.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_columns = X_train.columns\n",
    "X_train_ids = X_train['id']\n",
    "del X_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: funder\n",
      "c: installer\n",
      "c: wpt_name\n",
      "c: basin\n",
      "c: subvillage\n",
      "c: region\n",
      "c: region_code\n",
      "c: district_code\n",
      "c: lga\n",
      "c: ward\n",
      "c: public_meeting\n",
      "c: scheme_management\n",
      "c: scheme_name\n",
      "c: permit\n",
      "c: extraction_type\n",
      "c: extraction_type_group\n",
      "c: extraction_type_class\n",
      "c: management\n",
      "c: management_group\n",
      "c: payment\n",
      "c: payment_type\n",
      "c: water_quality\n",
      "c: quality_group\n",
      "c: quantity\n",
      "c: quantity_group\n",
      "c: source\n",
      "c: source_type\n",
      "c: source_class\n",
      "c: waterpoint_type\n",
      "c: waterpoint_type_group\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7fdd093c47e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         else (0 if np.issubdtype(type(x), np.number) else 'unknown'))\n\u001b[1;32m      8\u001b[0m     \u001b[0mxcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mxcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mycv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn_noisy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mycv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_to_reset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mxcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepr0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-62f99bf6b1f1>\u001b[0m in \u001b[0;36mspawn_noisy\u001b[0;34m(X, y, colsets_to_noise)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     X = pd.concat([copy_and_reset(X, cols).reset_index(drop=True)\n\u001b[0;32m--> 216\u001b[0;31m                   for cols in colsets_to_noise],\n\u001b[0m\u001b[1;32m    217\u001b[0m                  ignore_index=True)\n\u001b[1;32m    218\u001b[0m     y = np.concatenate([y\n",
      "\u001b[0;32m<ipython-input-3-62f99bf6b1f1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     X = pd.concat([copy_and_reset(X, cols).reset_index(drop=True)\n\u001b[0;32m--> 216\u001b[0;31m                   for cols in colsets_to_noise],\n\u001b[0m\u001b[1;32m    217\u001b[0m                  ignore_index=True)\n\u001b[1;32m    218\u001b[0m     y = np.concatenate([y\n",
      "\u001b[0;32m~/py/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   2886\u001b[0m             \u001b[0mnew_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m             \u001b[0mnew_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_casted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   3430\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3431\u001b[0m         \"\"\"\n\u001b[0;32m-> 3432\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3433\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep, mgr)\u001b[0m\n\u001b[1;32m   3434\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3435\u001b[0m         return self.apply('copy', axes=new_axes, deep=deep,\n\u001b[0;32m-> 3436\u001b[0;31m                           do_integrity_check=False)\n\u001b[0m\u001b[1;32m   3437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3090\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3091\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3092\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep, mgr)\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for c in cat_features_names(xcv):\n",
    "    if c not in xtr.columns: continue\n",
    "    cvals = set(xtr[c].unique())\n",
    "    # print('c: %s' % c)\n",
    "    def fill_cat(x):\n",
    "        return (x if x in cvals and not np.isnan(x)\n",
    "        else (0 if np.issubdtype(type(x), np.number) else 'unknown'))\n",
    "    xcv.loc[:,c] = xcv.loc[:,c].map(fill_cat)\n",
    "xcv, ycv = spawn_noisy(xcv, ycv, cols_to_reset)\n",
    "xcv = prepr0.transform(xcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in cat_features_names(xva):\n",
    "    if c not in xtr.columns: continue\n",
    "    cvals = set(xtr[c].unique())\n",
    "    xva.loc[:,c] = xva.loc[:,c].map(lambda x:\n",
    "                                    x if x in cvals and pd.notnull(x)\n",
    "                                    else (0 if np.issubdtype(x, np.number) else 'unknown'))\n",
    "xva, yva = spawn_noisy(xva, yva, cols_to_reset)\n",
    "xva = prepr0.transform(xva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_feats = [xtr.columns.get_loc(c) for c in [\n",
    "    'funder', 'installer', 'wpt_name', 'basin', 'subvillage',\n",
    "    'region', 'region_code', 'district_code', 'lga', 'ward',\n",
    "    'extraction_type',\n",
    "    'management', 'management_group', 'payment', 'payment_type', 'water_quality',\n",
    "    'quality_group', 'source', 'source_type', 'source_class',\n",
    "    'waterpoint_type', 'waterpoint_type_group'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = catboost.CatBoostClassifier(iterations=100,\n",
    "                                  loss_function='MultiClass',\n",
    "                                  eval_metric='Accuracy',\n",
    "                                  calc_feature_importances=True)\n",
    "clf.fit(xtr, ytr, eval_set=(xcv, ycv),\n",
    "        cat_features=cat_feats,\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(clf.score(xtr, ytr),\n",
    "        clf.score(xcv, ycv),\n",
    "        clf.score(xva, yva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_len = 59400 # X_train.shape[0]\n",
    "display(clf.score(xcv.iloc[:orig_len,:], ycv[:orig_len]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_te = X_test.copy()\n",
    "for c in cat_features_names(X_te):\n",
    "    if c not in xtr.columns: continue\n",
    "    cvals = set(xtr[c].unique())\n",
    "    X_te.loc[:,c] = X_te.loc[:,c].map(lambda x:\n",
    "                                    x if x in cvals and pd.notnull(x)\n",
    "                                    else (0 if np.issubdtype(x, np.number) else 'unknown'))\n",
    "# X_te.loc[:,'date_recorded'] = 'Unknown'\n",
    "X_te = prepr0.transform(X_te.drop('id', axis=1))\n",
    "y_te = y_enc.inverse_transform(clf.predict(X_te).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = pd.DataFrame({'status_group': y_te.ravel()}, index=X_test['id'])\n",
    "ans.index.name = 'id'\n",
    "ans.to_csv('ans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!head ans.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
