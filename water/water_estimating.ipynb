{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import bokeh.plotting\n",
    "import catboost\n",
    "import sklearn.preprocessing, sklearn.feature_selection, sklearn.model_selection\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "import sklearn.base\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import seaborn as sns\n",
    "import dateutil.parser\n",
    "import collections\n",
    "import sklearn.utils\n",
    "import itertools\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed = SEED\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_intersections(A, B, add_cat_feats=['date_recorded', 'construction_year',\n",
    "                                            'date_recorded_year', 'date_recorded_month']):\n",
    "    cat_features = np.where(np.array([(X_train[c].dtype == object)\n",
    "                                  or (c.endswith('code'))\n",
    "                                  or (c in add_cat_feats) for c in X_train.columns.values]))[0]\n",
    "    cat_feats_observed = []\n",
    "    for c in cat_features:\n",
    "        n_uni = len(set(A.iloc[:,c]).union(B.iloc[:,c]))\n",
    "        n_int = len(set(A.iloc[:,c]).intersection(B.iloc[:,c]))\n",
    "        n_te = len(set(A.iloc[:,c]))\n",
    "        cat_feats_observed.append((A.columns[c], n_int/n_uni, n_int/n_te))\n",
    "    cat_feats_observed = (\n",
    "        pd.DataFrame(cat_feats_observed, columns=['var', 'intersection/union', 'intersection/B'])\n",
    "        .sort_values('intersection/B')\n",
    "    )\n",
    "    return cat_feats_observed\n",
    "class HideMissingValues(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in X.columns:\n",
    "            if np.issubdtype(X[c].dtype, np.number):\n",
    "                X.loc[:,c].fillna(X.loc[:,c].median(), inplace=True)\n",
    "            else:\n",
    "                X.loc[:,c].fillna('Unknown', inplace=True)\n",
    "                X.loc[:,c] = X[c].map(lambda x: str(x))\n",
    "        return X\n",
    "    \n",
    "    \n",
    "class DropGarbage(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=['id', 'funder', 'recorded_by', 'date_recorded']):\n",
    "        self.cols = cols\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.drop(self.cols, axis=1, errors='ignore')\n",
    "\n",
    "class SplitDate(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col):\n",
    "        self.col = col\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        def t(x):\n",
    "            if isinstance(x, str):\n",
    "                x = dateutil.parser.parse(x)\n",
    "            return (x.year, x.month, x.day, x.weekday())\n",
    "        X = X.copy()\n",
    "        (X.loc[:, self.col + '_year'],\n",
    "         X.loc[:, self.col + '_month'],\n",
    "         X.loc[:, self.col + '_day'],\n",
    "         X.loc[:, self.col + '_weekday']) = zip(\n",
    "        *X.loc[:, self.col].map(t))\n",
    "        return X\n",
    "\n",
    "    \n",
    "class HandyFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X.loc[:,'amount_per_man'] = X.loc[:,'amount_tsh']/X.loc[:,'population']\n",
    "        return X\n",
    "\n",
    "class OutcomeFrequences(BaseException, TransformerMixin):\n",
    "    def __init__(self, groupby, drop=False):\n",
    "        self.groupby = groupby\n",
    "        self.drop = drop\n",
    "        self.cnts_ = None\n",
    "        self.fq_cols_ = None\n",
    "        self.unknowns_ = 0\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        possible_outcomes = [_.split()[-1] if isinstance(_, str) else _ for _ in np.unique(y)]\n",
    "        n_outs = len(possible_outcomes)\n",
    "        self.cnts_ = collections.defaultdict(lambda: np.zeros(n_outs))\n",
    "        # print(self.groupby)\n",
    "        igroupby = np.array([X.columns.get_loc(_) for _ in self.groupby])\n",
    "        for i in range(X.shape[0]):\n",
    "            # assuming $y$ is label-encoded\n",
    "            keys, out = tuple(X.iloc[i, igroupby].values), y[i]\n",
    "            self.cnts_[keys][out] += 1 # no of `(keys, out)` occurences\n",
    "        for k in self.cnts_:\n",
    "            self.cnts_[k] //= self.cnts_[k].sum()\n",
    "            \n",
    "        self.possible_outcomes_ = possible_outcomes\n",
    "        self.fq_cols_ = ['_'.join(self.groupby + [str(out), 'fq'],) for out in possible_outcomes]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        self.unknowns_ = 0\n",
    "        igroupby = np.array([X.columns.get_loc(_) for _ in self.groupby])\n",
    "        new_cols = [tuple([None for out in self.possible_outcomes_]) for _ in range(X.shape[0])]\n",
    "        for i in range(X.shape[0]):\n",
    "            keys = tuple(X.iloc[i, igroupby].values)\n",
    "            if keys in self.cnts_:\n",
    "                new_cols[i] = tuple([self.cnts_[keys][out] for out in self.possible_outcomes_])\n",
    "            else:\n",
    "                self.unknowns_ += 1\n",
    "        self.unknowns_ /= X.size\n",
    "        # print(str(X)[:100])\n",
    "        # print(str(new_cols)[:100])\n",
    "        # print(str(self.fq_cols_[:100]))\n",
    "        new_cols = pd.DataFrame(new_cols, columns=self.fq_cols_)\n",
    "        for c in self.fq_cols_:\n",
    "            new_cols.loc[:,c].fillna(0, inplace=True) # new_cols.loc[:,c].median(), inplace=True)\n",
    "        X = pd.concat((X, new_cols,), axis=1)\n",
    "        if self.drop:\n",
    "            X.drop(self.groupby, axis=1, inplace=True, errors='ignore')\n",
    "        return X\n",
    "\n",
    "class ExplicitAge(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X.loc[:, 'age'] = X.loc[:,'date_recorded_year'] - X.loc[:,'construction_year']\n",
    "        return X\n",
    "def split_train_cv_test(X, y, proportions=(.75, .25/2, .25/2)):\n",
    "    # expecting $y$ to be numpy array\n",
    "    outs = np.unique(y)\n",
    "    proportions = np.array(proportions)\n",
    "    classes = [np.where(y == i)[0] for i in outs]\n",
    "    xparts = [[] for _ in proportions]\n",
    "    yparts = [[] for _ in proportions]\n",
    "    for cidx in classes:\n",
    "        cidx = sklearn.utils.shuffle(cidx)\n",
    "        cprops = cidx.size * proportions\n",
    "        cprops = cprops.astype(int)\n",
    "        cprops[-1] = cidx.size - cprops[:-1].sum()\n",
    "        cx = X.iloc[cidx,:]\n",
    "        cy = y[cidx]\n",
    "        for xpart, ypart, sz in zip(xparts, yparts, cprops):\n",
    "            xpart.append(cx.iloc[:sz,:])\n",
    "            ypart.append(cy[:sz])\n",
    "            cx, cy = cx.iloc[sz:,:], cy[sz:]\n",
    "    xparts = [pd.concat(xpart) for xpart in xparts]\n",
    "    yparts = [np.concatenate(ypart) for ypart in yparts]\n",
    "    # parts = []\n",
    "    # print(len(xparts), 'parts')\n",
    "    # for xpart, ypart in zip(xparts, yparts):\n",
    "    #     parts.append(xpart)\n",
    "    #     parts.append(ypart)\n",
    "    parts = xparts + yparts\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepr_and_catboost(X_tr, X_cv, X_te,\n",
    "                       y_tr, y_cv, y_te,\n",
    "                       X_test,\n",
    "                       prepr=None, outfname='ans.csv',\n",
    "                       catboost_args = [],\n",
    "                       catboost_kvargs = {\n",
    "                           'random_seed': SEED,\n",
    "                           'loss_function': 'MultiClass',\n",
    "                           'verbose': True,\n",
    "                           'calc_feature_importance': True,\n",
    "                       }):\n",
    "    if prepr is not None:\n",
    "        X_tr = prepr.transform(X_tr)\n",
    "        X_cv = prepr.transform(X_cv)\n",
    "        X_te = prepr.transform(X_te)\n",
    "        X_test = prepr.transform(X_test)\n",
    "    clf = catboost.CatBoostClassifier(*catboost_args, **catboost_kvargs)\n",
    "    clf.fit(X_tr, y_tr,\n",
    "         cat_features=np.where(np.array([(X_tr[c].dtype == object)\n",
    "                                  or (c.endswith('code')) or ('date' in c)\n",
    "                                         for c in X_tr.columns.values]))[0])\n",
    "    y_test = clf.predict(X_test)\n",
    "    display('train score: %s' % clf.score(X_tr, y_tr))\n",
    "    display('cv score: %s' % clf.score(X_cv, y_cv))\n",
    "    display('test score: %s' % clf.score(X_te, y_te))\n",
    "    ans=pd.DataFrame({'status_group': y_enc.inverse_transform(\n",
    "        y_test.astype(int).ravel())},\n",
    "                         index= X_test.iloc[:,0].values)\n",
    "    ans.index.name = 'id'\n",
    "    ans.to_csv(name)\n",
    "    return clf, X_tr, X_cv, X_te, y_tr, y_cv, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['functional', 'functional needs repair', 'non functional'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_enc = sklearn.preprocessing.LabelEncoder()\n",
    "y_enc.fit(pd.Series.from_csv('out_classes.csv'))\n",
    "y_enc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_cv, X_va, y_tr, y_cv, y_va, X_te = [\n",
    "    pd.read_csv(fname) for fname in ['X_tr.csv', 'X_cv.csv', 'X_va.csv',\n",
    "                                     'y_tr.csv', 'y_cv.csv', 'y_va.csv',\n",
    "                                     'X_te.csv',]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prepr_and_catboost(X_tr, X_cv, X_va, y_tr, y_cv, y_va, X_te,\n",
    "                   outfname='ans1.csv',\n",
    "                   prepr=DropGarbage([c for c in X_tr.columns\n",
    "                      if re.match('.*(date|wpt_name|installer|funder|subvillage).*', c, re.IGNORECASE)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
