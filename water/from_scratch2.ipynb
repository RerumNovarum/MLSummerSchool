{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import bokeh.plotting\n",
    "import keras, keras.models, keras.layers\n",
    "import sklearn.preprocessing, sklearn.feature_selection, sklearn.model_selection\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "import sklearn.base\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import seaborn as sns\n",
    "import dateutil.parser\n",
    "import collections\n",
    "import sklearn.utils\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed = SEED\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport numpy as np\n",
    "\n",
    "cpdef float qtof_(x):\n",
    "    qtys = {\n",
    "        'enough': 1.0,\n",
    "        'insufficient': .6,\n",
    "        'seasonal': .4,\n",
    "        'dry': .2,\n",
    "        'unknown': 0,\n",
    "    }\n",
    "    if x in qtys:\n",
    "        return qtys[x]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>intersection/union</th>\n",
       "      <th>intersection/B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wpt_name</td>\n",
       "      <td>0.055950</td>\n",
       "      <td>0.068342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>subvillage</td>\n",
       "      <td>0.294315</td>\n",
       "      <td>0.326939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>installer</td>\n",
       "      <td>0.343011</td>\n",
       "      <td>0.385368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>funder</td>\n",
       "      <td>0.344699</td>\n",
       "      <td>0.388830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>scheme_name</td>\n",
       "      <td>0.563960</td>\n",
       "      <td>0.599926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date_recorded</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>scheme_management</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ward</td>\n",
       "      <td>0.930887</td>\n",
       "      <td>0.933556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>extraction_type</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>region_code</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>payment_type</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>water_quality</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>quantity_group</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>quantity</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>payment</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>source</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>source_type</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>source_class</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>quality_group</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>management_group</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>construction_year</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>extraction_type_class</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>extraction_type_group</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>waterpoint_type</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>permit</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>recorded_by</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>public_meeting</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lga</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>district_code</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>region</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>basin</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>management</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>waterpoint_type_group</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      var  intersection/union  intersection/B\n",
       "3                wpt_name            0.055950        0.068342\n",
       "5              subvillage            0.294315        0.326939\n",
       "2               installer            0.343011        0.385368\n",
       "1                  funder            0.344699        0.388830\n",
       "14            scheme_name            0.563960        0.599926\n",
       "0           date_recorded            0.861789        0.893258\n",
       "13      scheme_management            0.923077        0.923077\n",
       "10                   ward            0.930887        0.933556\n",
       "17        extraction_type            0.944444        0.944444\n",
       "7             region_code            0.962963        0.962963\n",
       "23           payment_type            1.000000        1.000000\n",
       "24          water_quality            1.000000        1.000000\n",
       "27         quantity_group            1.000000        1.000000\n",
       "26               quantity            1.000000        1.000000\n",
       "22                payment            1.000000        1.000000\n",
       "28                 source            1.000000        1.000000\n",
       "29            source_type            1.000000        1.000000\n",
       "30           source_class            1.000000        1.000000\n",
       "25          quality_group            1.000000        1.000000\n",
       "21       management_group            1.000000        1.000000\n",
       "16      construction_year            1.000000        1.000000\n",
       "19  extraction_type_class            1.000000        1.000000\n",
       "18  extraction_type_group            1.000000        1.000000\n",
       "31        waterpoint_type            1.000000        1.000000\n",
       "15                 permit            1.000000        1.000000\n",
       "12            recorded_by            1.000000        1.000000\n",
       "11         public_meeting            1.000000        1.000000\n",
       "9                     lga            1.000000        1.000000\n",
       "8           district_code            1.000000        1.000000\n",
       "6                  region            1.000000        1.000000\n",
       "4                   basin            1.000000        1.000000\n",
       "20             management            1.000000        1.000000\n",
       "32  waterpoint_type_group            1.000000        1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(59400, 40)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(59400, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(14850, 40)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting installer_fq\n",
      "applying installer_fq to test\n",
      "fitting subvillage_fq\n",
      "applying subvillage_fq to test\n",
      "fitting basin_fq\n",
      "applying basin_fq to test\n",
      "fitting extraction_type_class_fq\n",
      "applying extraction_type_class_fq to test\n",
      "fitting date_recorded_month_fq\n",
      "applying date_recorded_month_fq to test\n",
      "fitting region_fq\n",
      "applying region_fq to test\n",
      "fitting ward_fq\n",
      "applying ward_fq to test\n",
      "fitting source_type_fq\n",
      "applying source_type_fq to test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sizes: RangeIndex(start=0, stop=540514, step=1) 540514'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LabelencodeAll:\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        self.encs_ = collections.defaultdict(sklearn.preprocessing.LabelEncoder)\n",
    "    def fit(self, X, y=None):\n",
    "        for c in self.cols:\n",
    "            if c not in X.columns: continue\n",
    "            if not np.issubdtype(X[c].dtype, np.number):\n",
    "                self.encs_[c].fit(X[c])\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c, enc in self.encs_.items():\n",
    "            if c not in X.columns: continue\n",
    "            if not c in X.columns: continue\n",
    "            if not np.issubdtype(X.loc[:,c].dtype, np.number):\n",
    "                X.loc[:,c] = enc.transform(X.loc[:,c])\n",
    "        return X\n",
    "\n",
    "class DecodeQuantity(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col):\n",
    "        self.col = col\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X.loc[:,self.col] = X.loc[:,self.col].map(qtof_)\n",
    "        return X\n",
    "    \n",
    "    \n",
    "class HideMissingValues(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in X.columns:\n",
    "            if np.issubdtype(X.loc[:,c].dtype, np.number):\n",
    "                med = X.loc[:,c].median()\n",
    "                if np.isnan(med):\n",
    "                    med = 0\n",
    "                X.loc[:,c].fillna(med, inplace=True)\n",
    "            elif set(X.loc[:,c].unique()).issubset({True, False, np.nan}):\n",
    "                X.loc[X.loc[:,c] == 1, c] = 1\n",
    "                X.loc[X.loc[:,c] != 1, c] = 0\n",
    "                X.loc[:,c].fillna(0.5, inplace=True)\n",
    "            else:\n",
    "                X.loc[:,c].fillna('unknown', inplace=True)\n",
    "                X.loc[:,c] = X.loc[:,c].astype('str')\n",
    "        return X\n",
    "    \n",
    "\n",
    "class DropGarbage(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=['id', 'funder', 'recorded_by', 'date_recorded']):\n",
    "        self.cols = cols\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.drop(self.cols, axis=1, errors='ignore')\n",
    "\n",
    "class SplitDate(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col, drop=True):\n",
    "        self.col = col\n",
    "        self.drop = drop\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        def t(x):\n",
    "            if isinstance(x, str):\n",
    "                try:\n",
    "                    x = dateutil.parser.parse(x)\n",
    "                except:\n",
    "                    return (np.nan, np.nan, np.nan, np.nan)\n",
    "            elif pd.isnull(x):\n",
    "                return (np.nan, np.nan, np.nan, np.nan)\n",
    "            return (x.year, x.month, x.day, x.weekday())\n",
    "        X = X.copy()\n",
    "        (X.loc[:, self.col + '_year'],\n",
    "         X.loc[:, self.col + '_month'],\n",
    "         X.loc[:, self.col + '_day'],\n",
    "         X.loc[:, self.col + '_weekday']) = zip(\n",
    "        *X.loc[:, self.col].map(t))\n",
    "        if self.drop:\n",
    "            X.drop(self.col, axis=1, inplace=True)\n",
    "        return X\n",
    "\n",
    "    \n",
    "class HandyFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X.loc[:,'amount_per_man'] = (X.loc[:,'amount_tsh']/X.loc[:,'population']).fillna(0)\n",
    "        return X\n",
    "\n",
    "class OutcomeFrequences(BaseException, TransformerMixin):\n",
    "    def __init__(self, groupby, drop=False, return_only_fq=False):\n",
    "        self.groupby = groupby\n",
    "        self.drop = drop\n",
    "        self.cnts_ = None\n",
    "        self.fq_cols_ = None\n",
    "        self.return_only_fq = return_only_fq\n",
    "        self.unknowns_ = 0\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        possible_outcomes = [_.split()[-1] if isinstance(_, str) else _ for _ in np.unique(y)]\n",
    "        n_outs = len(possible_outcomes)\n",
    "        self.cnts_ = collections.defaultdict(lambda: np.zeros(n_outs))\n",
    "        # print(self.groupby)\n",
    "        igroupby = np.array([X.columns.get_loc(_) for _ in self.groupby])\n",
    "        for i in range(X.shape[0]):\n",
    "            # assuming $y$ is label-encoded\n",
    "            keys, out = tuple(X.iloc[i, igroupby].values), y[i]\n",
    "            self.cnts_[keys][out] += 1 # no of `(keys, out)` occurences\n",
    "        for k in self.cnts_:\n",
    "            self.cnts_[k] //= self.cnts_[k].sum()\n",
    "            \n",
    "        self.possible_outcomes_ = possible_outcomes\n",
    "        self.fq_cols_ = ['_'.join(self.groupby + [str(out), 'fq'],) for out in possible_outcomes]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        self.unknowns_ = 0\n",
    "        igroupby = np.array([X.columns.get_loc(_) for _ in self.groupby])\n",
    "        new_cols = [tuple([None for out in self.possible_outcomes_]) for _ in range(X.shape[0])]\n",
    "        for i in range(X.shape[0]):\n",
    "            keys = tuple(X.iloc[i, igroupby].values)\n",
    "            if keys in self.cnts_:\n",
    "                new_cols[i] = tuple([self.cnts_[keys][out] for out in self.possible_outcomes_])\n",
    "            else:\n",
    "                self.unknowns_ += 1\n",
    "        self.unknowns_ /= X.size\n",
    "        # print(str(X)[:100])\n",
    "        # print(str(new_cols)[:100])\n",
    "        # print(str(self.fq_cols_[:100]))\n",
    "        new_cols = pd.DataFrame(new_cols, columns=self.fq_cols_)\n",
    "        for c in self.fq_cols_:\n",
    "            new_cols.loc[:,c].fillna(0, inplace=True) # new_cols.loc[:,c].median(), inplace=True)\n",
    "        if self.return_only_fq:\n",
    "            return new_cols\n",
    "        X = pd.concat((X, new_cols,), axis=1)\n",
    "        if self.drop:\n",
    "            X.drop(self.groupby, axis=1, inplace=True, errors='ignore')\n",
    "        return X\n",
    "\n",
    "class ExplicitAge(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X.loc[:, 'age'] = X.loc[:,'date_recorded_year'] - X.loc[:,'construction_year']\n",
    "        return X\n",
    "\n",
    "def show_intersections(A, B, add_cat_feats=['date_recorded', 'construction_year',\n",
    "                                            'date_recorded_year', 'date_recorded_month']):\n",
    "    cat_features = np.where(np.array([(X_train[c].dtype == object)\n",
    "                                  or (c.endswith('code'))\n",
    "                                  or (c in add_cat_feats) for c in X_train.columns.values]))[0]\n",
    "    cat_feats_observed = []\n",
    "    for c in cat_features:\n",
    "        n_uni = len(set(A.iloc[:,c]).union(B.iloc[:,c]))\n",
    "        n_int = len(set(A.iloc[:,c]).intersection(B.iloc[:,c]))\n",
    "        n_te = len(set(A.iloc[:,c]))\n",
    "        cat_feats_observed.append((A.columns[c], n_int/n_uni, n_int/n_te))\n",
    "    cat_feats_observed = (\n",
    "        pd.DataFrame(cat_feats_observed, columns=['var', 'intersection/union', 'intersection/B'])\n",
    "        .sort_values('intersection/B')\n",
    "    )\n",
    "    return cat_feats_observed\n",
    "\n",
    "        \n",
    "def split_train_cv_test(X, y, proportions=(.75, .25/2, .25/2)):\n",
    "    # expecting $y$ to be numpy array\n",
    "    outs = np.unique(y)\n",
    "    proportions = np.array(proportions)\n",
    "    classes = [np.where(y == i)[0] for i in outs]\n",
    "    xparts = [[] for _ in proportions]\n",
    "    yparts = [[] for _ in proportions]\n",
    "    for cidx in classes:\n",
    "        cidx = sklearn.utils.shuffle(cidx)\n",
    "        cprops = cidx.size * proportions\n",
    "        cprops = cprops.astype(int)\n",
    "        cprops[-1] = cidx.size - cprops[:-1].sum()\n",
    "        # print(cidx)\n",
    "        cx = X.iloc[cidx,:]\n",
    "        cy = y[cidx]\n",
    "        for xpart, ypart, sz in zip(xparts, yparts, cprops):\n",
    "            xpart.append(cx.iloc[:sz,:])\n",
    "            ypart.append(cy[:sz])\n",
    "            cx, cy = cx.iloc[sz:,:], cy[sz:]\n",
    "    xparts = [pd.concat(xpart) for xpart in xparts]\n",
    "    yparts = [np.concatenate(ypart) for ypart in yparts]\n",
    "    parts = xparts + yparts\n",
    "    return parts\n",
    "def cat_features_indices(X):\n",
    "    return np.where(np.array([(X[c].dtype == object)\n",
    "        or (c.endswith('code'))                                                  \n",
    "    for c in X.columns.values]))[0]\n",
    "\n",
    "def cat_features_names(X):\n",
    "    return X.columns[cat_features_indices(X)]\n",
    "\n",
    "def copy_and_reset(X, cols, save=False, cat_unknown='unknown', num_unknown=0):\n",
    "    X = X.copy()\n",
    "    for c in X.columns:\n",
    "        if save and c in cols:\n",
    "            continue\n",
    "        if not save and c not in cols:\n",
    "            continue\n",
    "        if X[c].dtype == object:\n",
    "            X.loc[:,c] = cat_unknown\n",
    "        else:\n",
    "            X.loc[:,c] = num_unknown\n",
    "    return X\n",
    "\n",
    "def spawn_noisy(X, y, colsets_to_reset=[], colsets_to_save=None):\n",
    "    X = X.drop('id', axis=1, errors='ignore').copy()\n",
    "    colsets = colsets_to_reset if colsets_to_save is None else colsets_to_save\n",
    "    X = pd.concat([copy_and_reset(X, cols,\n",
    "                                  save=colsets_to_save is not None).reset_index(drop=True)\n",
    "                  for cols in colsets],\n",
    "                 ignore_index=True)\n",
    "    y = np.concatenate([y\n",
    "                  for cols in colsets])\n",
    "    return X.reset_index(drop=True), y\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "display(show_intersections(X_train, X_test))\n",
    "display(X_train.shape, y_train.shape, X_test.shape)\n",
    "class PrefitedPipeline:\n",
    "    def __init__(self, steps, verbose=1):\n",
    "        self.steps = steps\n",
    "        self.verbose = verbose\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if self.verbose > 2:\n",
    "            print('Input columns: %s' % X.columns)\n",
    "        for stepname, step in self.steps:\n",
    "            if self.verbose > 0:\n",
    "                print('Executing %s' % stepname)\n",
    "            X = step.transform(X)\n",
    "            if self.verbose > 2:\n",
    "                print('Step %s output columns: %s' % (stepname,\n",
    "                                                      X.columns if isinstance(X, pd.DataFrame)\n",
    "                                                      else type(X)))\n",
    "        return X\n",
    "    \n",
    "y_enc = sklearn.preprocessing.LabelEncoder()\n",
    "ytr = y_enc.fit_transform(y_train.iloc[:,1])\n",
    "\n",
    "preprqty = DecodeQuantity('quantity')\n",
    "xtr = preprqty.fit_transform(X_train)\n",
    "xte = preprqty.fit_transform(X_test)\n",
    "\n",
    "xtr.drop(['id', 'num_private', 'recorded_by', 'wpt_name'], axis=1, errors='ignore', inplace=True)\n",
    "xte.drop(['id', 'num_private', 'recorded_by', 'wpt_name'], axis=1, errors='ignore', inplace=True)\n",
    "\n",
    "preprdate = SplitDate('date_recorded', drop=True)\n",
    "xtr = preprdate.fit_transform(xtr)\n",
    "xte = preprdate.transform(xte)\n",
    "preprage = ExplicitAge()\n",
    "xtr = preprage.fit_transform(xtr)\n",
    "xte = preprage.transform(xte)\n",
    "\n",
    "xtr.loc[:,cat_features_names(xtr)] = 'unknown'\n",
    "xte.loc[:,cat_features_names(xte)] = 'unknown'\n",
    "\n",
    "xlabelenc = LabelencodeAll(cols=cat_features_names(xtr))\n",
    "xlabelenc.fit(pd.concat((xtr, xte)))\n",
    "xtr = xlabelenc.transform(xtr)\n",
    "xte = xlabelenc.transform(xte)\n",
    "\n",
    "hmv_ = HideMissingValues()\n",
    "xtr = hmv_.fit_transform(xtr)\n",
    "xte = hmv_.transform(xte)\n",
    "\n",
    "hf_ = HandyFeatures()\n",
    "xtr = hf_.fit_transform(xtr)\n",
    "xte = hf_.transform(xte)\n",
    "\n",
    "xtr.drop(['date_recorded_day', 'date_recorded_weekday'], axis=1, errors='ignore', inplace=True)\n",
    "xte.drop(['date_recorded_day', 'date_recorded_weekday'], axis=1, errors='ignore', inplace=True)\n",
    "\n",
    "fqpreprs = [(catcol + '_fq', OutcomeFrequences([catcol], drop=False))\n",
    "    for catcol in ['installer', 'subvillage', 'basin', 'extraction_type_class',\n",
    "                   'date_recorded_month', 'region', 'ward', 'source_type']\n",
    "]\n",
    "for i in range(len(fqpreprs)):\n",
    "    print('fitting %s' % fqpreprs[i][0])\n",
    "    xtr = fqpreprs[i][1].fit_transform(xtr, ytr)\n",
    "    print('applying %s to test' % fqpreprs[i][0])\n",
    "    xte = fqpreprs[i][1].transform(xte)\n",
    "\n",
    "\n",
    "xtr, xcv, xva, ytr, ycv, yva = split_train_cv_test(xtr, ytr, proportions=(.7, .15, .15))\n",
    "\n",
    "\n",
    "cols_to_reset = [\n",
    "    [],\n",
    "    ['date_recorded_month'],\n",
    "    ['subvillage'],\n",
    "    [ 'installer', 'funder'],\n",
    "    [ 'subvillage', 'installer', 'funder', 'date_recorded_month' ],\n",
    "    [ 'subvillage', 'installer', 'funder',\n",
    "     'scheme_name', 'ward', 'region_code', ],\n",
    "    [ 'subvillage', 'installer', 'funder',\n",
    "     'scheme_management', 'ward', 'region_code', 'date_recorded_month'],\n",
    "]\n",
    "\n",
    "cols_to_save = [\n",
    "    ['age', 'amount_per_man','extraction_type',\n",
    "     'water_quality', 'quality_group', 'source', 'source_type', 'source_class',\n",
    "     'waterpoint_type', 'waterpoint_type_group'],\n",
    "    ['date_recorded_month', 'age', 'amount_tsh', 'population',\n",
    "     'amount_per_man','extraction_type', 'longtitude', 'latitude'\n",
    "     'water_quality', 'quality_group', 'source', 'source_type', 'source_class',\n",
    "     'waterpoint_type', 'waterpoint_type_group'],\n",
    "    ['date_recorded_month', 'age', 'amount_tsh', 'population',\n",
    "     'amount_per_man','extraction_type', 'longtitude', 'latitude'\n",
    "     'water_quality', 'quality_group', 'source', 'source_type', 'source_class',\n",
    "     'waterpoint_type', 'waterpoint_type_group'],\n",
    "    ['date_recorded_month', 'age', 'amount_tsh', 'population',\n",
    "     'amount_per_man','extraction_type', 'longtitude', 'latitude'\n",
    "     'water_quality', 'quality_group', 'source', 'source_type', 'source_class',\n",
    "     'waterpoint_type', 'waterpoint_type_group'],\n",
    "    ['date_recorded_month', 'age', 'amount_tsh', 'population',\n",
    "     'amount_per_man','extraction_type', 'longtitude', 'latitude'\n",
    "     'water_quality', 'quality_group', 'source', 'source_type', 'source_class',\n",
    "     'waterpoint_type', 'waterpoint_type_group'],\n",
    "    ['date_recorded_month', 'age', 'amount_tsh', 'population',\n",
    "     'amount_per_man','extraction_type', 'longtitude', 'latitude'\n",
    "     'water_quality', 'quality_group', 'source', 'source_type', 'source_class',\n",
    "     'waterpoint_type', 'waterpoint_type_group']\n",
    "]\n",
    "\n",
    "cbc_cat_feats = [xtr.columns.get_loc(c) for c in [\n",
    "    'funder', 'installer', 'basin', 'subvillage',\n",
    "    'region', 'region_code', 'district_code', 'lga', 'ward',\n",
    "    'extraction_type',\n",
    "    'management', 'management_group', 'payment', 'payment_type', 'water_quality',\n",
    "    'quality_group', 'source', 'source_type', 'source_class',\n",
    "    'waterpoint_type', 'waterpoint_type_group'\n",
    "]]\n",
    "\n",
    "xtr, ytr = [pd.concat((a.reset_index(drop=True), b.reset_index(drop=True),),\n",
    "                      ignore_index=True) if isinstance(a, pd.DataFrame)\n",
    "            else np.concatenate((a,b)) for a,b in zip(\n",
    "    spawn_noisy(xtr, ytr, cols_to_reset),\n",
    "    spawn_noisy(xtr, ytr, colsets_to_save=cols_to_save))]\n",
    "                     \n",
    "display('sizes: %s %s' % (xtr.index, ytr.size))\n",
    "\n",
    "xcv, ycv = spawn_noisy(xcv, ycv, colsets_to_save=[xcv.columns, xcv.columns] + cols_to_save)\n",
    "\n",
    "xva, yva = spawn_noisy(xva, yva, colsets_to_save=[xva.columns, xva.columns] + cols_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ybinarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "ytr = ybinarizer.fit_transform(ytr)\n",
    "ycv = ybinarizer.transform(ycv)\n",
    "yva = ybinarizer.transform(yva)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = keras.models.Sequential([\n",
    "    keras.layers.Dense(xtr.shape[1], input_shape=(xtr.shape[1],)),\n",
    "    keras.layers.Activation('softmax'),\n",
    "    keras.layers.Dense(25),\n",
    "    keras.layers.Activation('softmax'),\n",
    "    keras.layers.Dense(y_enc.classes_.size),\n",
    "    keras.layers.Activation('softmax'),\n",
    "])\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "# xtr = scaler.fit_transform(xtr)\n",
    "m.compile(loss=keras.losses.categorical_crossentropy,\n",
    "          optimizer='sgd',\n",
    "          metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 2/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 3/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 4/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 5/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 6/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 7/20\n",
      "540514/540514 [==============================] - 12s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 8/20\n",
      "540514/540514 [==============================] - 12s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 9/20\n",
      "540514/540514 [==============================] - 12s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 10/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    - ETA: 0s - loss: nan - categor\n",
      "Epoch 11/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 12/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 13/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 14/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 15/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 16/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 17/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 18/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 19/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n",
      "Epoch 20/20\n",
      "540514/540514 [==============================] - 13s - loss: nan - categorical_accuracy: 0.5431    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb822e6d860>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(xtr.values, ytr, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
