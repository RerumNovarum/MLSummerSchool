{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suffering niggas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import bokeh.plotting\n",
    "import catboost\n",
    "import sklearn.preprocessing, sklearn.feature_selection, sklearn.model_selection\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "import sklearn.base\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed = SEED\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 40)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['id', 'amount_tsh', 'date_recorded', 'funder', 'gps_height',\n",
       "       'installer', 'longitude', 'latitude', 'wpt_name', 'num_private',\n",
       "       'basin', 'subvillage', 'region', 'region_code', 'district_code', 'lga',\n",
       "       'ward', 'population', 'public_meeting', 'recorded_by',\n",
       "       'scheme_management', 'scheme_name', 'permit', 'construction_year',\n",
       "       'extraction_type', 'extraction_type_group', 'extraction_type_class',\n",
       "       'management', 'management_group', 'payment', 'payment_type',\n",
       "       'water_quality', 'quality_group', 'quantity', 'quantity_group',\n",
       "       'source', 'source_type', 'source_class', 'waterpoint_type',\n",
       "       'waterpoint_type_group'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh                   0\n",
       "date_recorded                0\n",
       "funder                    3635\n",
       "gps_height                   0\n",
       "installer                 3655\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "num_private                  0\n",
       "basin                        0\n",
       "subvillage                 371\n",
       "region                       0\n",
       "region_code                  0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population                   0\n",
       "public_meeting            3334\n",
       "recorded_by                  0\n",
       "scheme_management         3877\n",
       "scheme_name              28166\n",
       "permit                    3056\n",
       "construction_year            0\n",
       "extraction_type              0\n",
       "extraction_type_group        0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "management_group             0\n",
       "payment                      0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quality_group                0\n",
       "quantity                     0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "source_type                  0\n",
       "source_class                 0\n",
       "waterpoint_type              0\n",
       "waterpoint_type_group        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    X_train.shape,\n",
    "    X_train.columns,\n",
    "    X_train.isnull().sum(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount_tsh                     [dtype('float64'), 6000.0, 0.0, 25.0, 20.0]\n",
       "basin                    [dtype('O'), 'Lake Nyasa', 'Lake Victoria', 'P...\n",
       "construction_year                 [dtype('int64'), 1999, 2010, 2009, 1986]\n",
       "date_recorded            [dtype('O'), '2011-03-14', '2013-03-06', '2013...\n",
       "district_code                                [dtype('int64'), 5, 2, 4, 63]\n",
       "extraction_type          [dtype('O'), 'gravity', 'submersible', 'swn 80...\n",
       "extraction_type_class    [dtype('O'), 'gravity', 'submersible', 'handpu...\n",
       "extraction_type_group    [dtype('O'), 'gravity', 'submersible', 'swn 80...\n",
       "funder                   [dtype('O'), 'Roman', 'Grumeti', 'Lottery Club...\n",
       "gps_height                          [dtype('int64'), 1390, 1399, 686, 263]\n",
       "id                             [dtype('int64'), 69572, 8776, 34310, 67743]\n",
       "installer                [dtype('O'), 'Roman', 'GRUMETI', 'World vision...\n",
       "latitude                 [dtype('float64'), -9.8563217699999992, -2.147...\n",
       "lga                      [dtype('O'), 'Ludewa', 'Serengeti', 'Simanjiro...\n",
       "longitude                [dtype('float64'), 34.938092750000003, 34.6987...\n",
       "management               [dtype('O'), 'vwc', 'wug', 'other', 'private o...\n",
       "management_group         [dtype('O'), 'user-group', 'other', 'commercia...\n",
       "num_private                                 [dtype('int64'), 0, 39, 5, 45]\n",
       "payment                  [dtype('O'), 'pay annually', 'never pay', 'pay...\n",
       "payment_type             [dtype('O'), 'annually', 'never pay', 'per buc...\n",
       "permit                                      [dtype('O'), False, True, nan]\n",
       "population                             [dtype('int64'), 109, 280, 250, 58]\n",
       "public_meeting                              [dtype('O'), True, nan, False]\n",
       "quality_group            [dtype('O'), 'good', 'salty', 'milky', 'unknown']\n",
       "quantity                 [dtype('O'), 'enough', 'insufficient', 'dry', ...\n",
       "quantity_group           [dtype('O'), 'enough', 'insufficient', 'dry', ...\n",
       "recorded_by                        [dtype('O'), 'GeoData Consultants Ltd']\n",
       "region                   [dtype('O'), 'Iringa', 'Mara', 'Manyara', 'Mtw...\n",
       "region_code                               [dtype('int64'), 11, 20, 21, 90]\n",
       "scheme_management        [dtype('O'), 'VWC', 'Other', nan, 'Private ope...\n",
       "scheme_name              [dtype('O'), 'Roman', nan, 'Nyumba ya mungu pi...\n",
       "source                   [dtype('O'), 'spring', 'rainwater harvesting',...\n",
       "source_class             [dtype('O'), 'groundwater', 'surface', 'unknown']\n",
       "source_type              [dtype('O'), 'spring', 'rainwater harvesting',...\n",
       "subvillage               [dtype('O'), 'Mnyusi B', 'Nyamara', 'Majengo',...\n",
       "ward                     [dtype('O'), 'Mundindi', 'Natta', 'Ngorika', '...\n",
       "water_quality            [dtype('O'), 'soft', 'salty', 'milky', 'unknown']\n",
       "waterpoint_type          [dtype('O'), 'communal standpipe', 'communal s...\n",
       "waterpoint_type_group    [dtype('O'), 'communal standpipe', 'hand pump'...\n",
       "wpt_name                 [dtype('O'), 'none', 'Zahanati', 'Kwa Mahundi'...\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series({c: ([X_train[c].dtype] + list(X_train[c].unique()[:4])).__repr__() for c in X_train.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group\n",
       "0  69572      functional\n",
       "1   8776      functional\n",
       "2  34310      functional\n",
       "3  67743  non functional\n",
       "4  19728      functional"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HideMissingValues(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in X.columns:\n",
    "            if np.issubdtype(X[c].dtype, np.number):\n",
    "                X.loc[:,c].fillna(X.loc[:,c].median(), inplace=True)\n",
    "            else:\n",
    "                X.loc[:,c].fillna('Unknown', inplace=True)\n",
    "                X.loc[:,c] = X[c].map(lambda x: str(x))\n",
    "        return X\n",
    "    \n",
    "    \n",
    "class DropGarbage(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=['id', 'funder', 'recorded_by', 'date_recorded']):\n",
    "        self.cols = cols\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.drop(self.cols, axis=1)\n",
    "\n",
    "class SplitDate(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col):\n",
    "        self.col = col\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        def t(x):\n",
    "            if isinstance(x, str):\n",
    "                x = dateutil.parser.parse(x)\n",
    "            return (x.year, x.month, x.day, x.weekday())\n",
    "        X = X.copy()\n",
    "        (X.loc[:, self.col + '_year'],\n",
    "         X.loc[:, self.col + '_month'],\n",
    "         X.loc[:, self.col + '_day'],\n",
    "         X.loc[:, self.col + '_weekday']) = zip(\n",
    "        *X.loc[:, self.col].map(t))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 28 01:42:21 MSK 2017\n",
      "Fri Jul 28 01:47:03 MSK 2017\n"
     ]
    }
   ],
   "source": [
    "prepr1 = Pipeline([\n",
    "    ('fillna', HideMissingValues()),\n",
    "    ('date_recorded', SplitDate('date_recorded')),\n",
    "    ('drop', DropGarbage(cols=['id', 'recorded_by', ]))\n",
    "])\n",
    "\n",
    "y_enc = sklearn.preprocessing.LabelEncoder()\n",
    "X = prepr1.fit_transform(X_train)\n",
    "y = y_enc.fit_transform(y_train.iloc[:,1])\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, train_size=0.66)\n",
    "\n",
    "!date\n",
    "cbc1 = catboost.CatBoostClassifier(random_seed=SEED,\n",
    "         loss_function='MultiClass',\n",
    "         eval_set=(X_te, y_te))\n",
    "cbc1.fit(X_tr,\n",
    "         y_tr,\n",
    "         cat_features=np.where(np.array([dt == object for dt in X.dtypes]))[0],\n",
    "         verbose=False)\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80550604080015842"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbc1.score(X_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6000.0, '2011-03-14'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0,[1,2]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,status_group\r\n",
      "50785,predicted label\r\n",
      "51630,predicted label\r\n",
      "17168,predicted label\r\n",
      "45559,predicted label\r\n",
      "49871,predicted label\r\n",
      "52449,predicted label\r\n",
      "24806,predicted label\r\n",
      "28965,predicted label\r\n",
      "36301,predicted label\r\n"
     ]
    }
   ],
   "source": [
    "!head SubmissionFormat.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test1 = cbc1.predict(prepr1.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 2.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test1[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ans1 = pd.DataFrame({'status_group': y_enc.inverse_transform(y_test1.astype(int).ravel())},\n",
    "                    index= X_test.iloc[:,0].values)\n",
    "ans1.index.name = 'id'\n",
    "ans1.to_csv('ans1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,status_group\r\n",
      "50785,functional\r\n",
      "51630,functional\r\n",
      "17168,functional\r\n",
      "45559,non functional\r\n",
      "49871,functional\r\n",
      "52449,functional\r\n",
      "24806,non functional\r\n",
      "28965,non functional\r\n",
      "36301,non functional\r\n"
     ]
    }
   ],
   "source": [
    "!head ans1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandyFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X.loc[:,'amount_per_man'] = X.loc[:,'amount_tsh']/X.loc[:,'population']\n",
    "        return X\n",
    "\n",
    "class OutcomeFrequences(BaseException, TransformerMixin):\n",
    "    def __init__(self, groupby):\n",
    "        self.groupby = groupby\n",
    "        self.cnts_ = None\n",
    "        self.fq_cols_ = None\n",
    "    def fit(self, X, y=None):\n",
    "        possible_outcomes = [_.split()[-1] if isinstance(_, str) else _ for _ in np.unique(y)]\n",
    "        n_outs = len(possible_outcomes)\n",
    "        self.cnts_ = collections.defaultdict(lambda: np.zeros(n_outs))\n",
    "        igroupby = np.array([X.columns.get_loc(_) for _ in self.groupby])\n",
    "        for i in range(X.shape[0]):\n",
    "            # assuming $y$ is label-encoded\n",
    "            keys, out = tuple(X.iloc[i, igroupby].values), y[i]\n",
    "            self.cnts_[keys][out] += 1 # no of `(keys, out)` occurences\n",
    "        for k in self.cnts_:\n",
    "            self.cnts_[k] /= self.cnts_[k].sum()\n",
    "            \n",
    "        self.possible_outcomes_ = possible_outcomes\n",
    "        self.fq_cols_ = ['_'.join(self.groupby + [str(out), 'fq'],) for out in possible_outcomes]\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        igroupby = np.array([X.columns.get_loc(_) for _ in self.groupby])\n",
    "        new_cols = [None for _ in range(X.shape[0])]\n",
    "        for i in range(X.shape[0]):\n",
    "            keys = tuple(X.iloc[i, igroupby].values)\n",
    "            if keys in self.cnts_:\n",
    "                new_cols[i] = tuple([self.cnts_[keys][out] for out in self.possible_outcomes_])\n",
    "        new_cols = pd.DataFrame(new_cols, columns=self.fq_cols_)\n",
    "        for c in self.fq_cols_:\n",
    "            new_cols.loc[:,c].fillna(new_cols.loc[:,c].median(), inplace=True)\n",
    "        X = pd.concat((X, new_cols,), axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prepr2 = Pipeline([\n",
    "    ('fillna', HideMissingValues()),\n",
    "    ('date_recorded', SplitDate('date_recorded')),\n",
    "    ('handyfeats', HandyFeatures()),\n",
    "    ('fq', OutcomeFrequences(['subvillage'])),\n",
    "    ('drop', DropGarbage(cols=['id', 'recorded_by']))\n",
    "])\n",
    "\n",
    "y_enc = sklearn.preprocessing.LabelEncoder()\n",
    "y = y_enc.fit_transform(y_train.iloc[:,1])\n",
    "X = prepr2.fit_transform(X_train, y)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, train_size=0.66)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "!date\n",
    "cbc2 = catboost.CatBoostClassifier(random_seed=SEED,\n",
    "         loss_function='MultiClass',\n",
    "         eval_set=(X_te, y_te))\n",
    "cbc2.fit(X_tr,\n",
    "         y_tr,\n",
    "         cat_features=np.where(np.array([dt == object for dt in X.dtypes]))[0],\n",
    "         verbose=False)\n",
    "!date\n",
    "display('score: %s' % cbc2.score(X_te, y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c43421ed51c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbc2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m ans2 = pd.DataFrame({'status_group': y_enc.inverse_transform(y_test2.astype(int).ravel())},\n\u001b[1;32m      4\u001b[0m                     index= X_test.iloc[:,0].values)\n\u001b[1;32m      5\u001b[0m \u001b[0mans2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-9f220140c1ac>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnts_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mnew_cols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpossible_outcomes_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mnew_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfq_cols_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfq_cols_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mnew_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    312\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   5615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5616\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[0;32m-> 5617\u001b[0;31m                                dtype=dtype)\n\u001b[0m\u001b[1;32m   5618\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5619\u001b[0m         return _list_of_dict_to_arrays(data, columns,\n",
      "\u001b[0;32m~/py/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   5689\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5690\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5691\u001b[0;31m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_object_array_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5692\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5693\u001b[0m         \u001b[0;31m# list of lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.to_object_array_tuples (pandas/_libs/lib.c:67655)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test2 = cbc2.predict(prepr2.transform(X_test))\n",
    "ans2 = pd.DataFrame({'status_group': y_enc.inverse_transform(y_test2.astype(int).ravel())},\n",
    "                    index= X_test.iloc[:,0].values)\n",
    "ans2.index.name = 'id'\n",
    "ans2.to_csv('ans2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.utils\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa! I overfited again! Drivendata scored it $0.8102$.\n",
    "We need some 1) diversification and 2) to validate model more carefully.\n",
    "We'll split train set into three parts this time and ensure we've got equal proportions of all classes in all of the (new_train, cv, test) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_cv_test(X, y, proportions=(.6, .1, .3)):\n",
    "    # expecting $y$ to be numpy array\n",
    "    outs = np.unique(y)\n",
    "    proportions = np.array(proportions)\n",
    "    classes = [np.where(y == i)[0] for i in outs]\n",
    "    xparts = [[] for _ in proportions]\n",
    "    yparts = [[] for _ in proportions]\n",
    "    for cidx in classes:\n",
    "        cidx = sklearn.utils.shuffle(cidx)\n",
    "        cprops = cidx.size * proportions\n",
    "        cprops = cprops.astype(int)\n",
    "        cprops[-1] = cidx.size - cprops[:-1].sum()\n",
    "        cx = X.iloc[cidx,:]\n",
    "        cy = y[cidx]\n",
    "        for xpart, ypart, sz in zip(xparts, yparts, cprops):\n",
    "            xpart.append(cx.iloc[:sz,:])\n",
    "            ypart.append(cy[:sz])\n",
    "            cx, cy = cx.iloc[sz:,:], cy[sz:]\n",
    "    xparts = [pd.concat(xpart) for xpart in xparts]\n",
    "    yparts = [np.concatenate(ypart) for ypart in yparts]\n",
    "    # parts = []\n",
    "    # print(len(xparts), 'parts')\n",
    "    # for xpart, ypart in zip(xparts, yparts):\n",
    "    #     parts.append(xpart)\n",
    "    #     parts.append(ypart)\n",
    "    parts = xparts + yparts\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutcomeFrequences2(BaseException, TransformerMixin):\n",
    "    def __init__(self, groupby, drop=False):\n",
    "        self.groupby = groupby\n",
    "        self.drop = drop\n",
    "        self.cnts_ = None\n",
    "        self.fq_cols_ = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        possible_outcomes = [_.split()[-1] if isinstance(_, str) else _ for _ in np.unique(y)]\n",
    "        n_outs = len(possible_outcomes)\n",
    "        self.cnts_ = collections.defaultdict(lambda: np.zeros(n_outs))\n",
    "        igroupby = np.array([X.columns.get_loc(_) for _ in self.groupby])\n",
    "        for i in range(X.shape[0]):\n",
    "            # assuming $y$ is label-encoded\n",
    "            keys, out = tuple(X.iloc[i, igroupby].values), y[i]\n",
    "            self.cnts_[keys][out] += 1 # no of `(keys, out)` occurences\n",
    "        for k in self.cnts_:\n",
    "            self.cnts_[k] //= self.cnts_[k].sum()\n",
    "            \n",
    "        self.possible_outcomes_ = possible_outcomes\n",
    "        self.fq_cols_ = ['_'.join(self.groupby + [str(out), 'fq'],) for out in possible_outcomes]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        igroupby = np.array([X.columns.get_loc(_) for _ in self.groupby])\n",
    "        new_cols = [[None for out in self.possible_outcomes_] for _ in range(X.shape[0])]\n",
    "        for i in range(X.shape[0]):\n",
    "            keys = tuple(X.iloc[i, igroupby].values)\n",
    "            if keys in self.cnts_:\n",
    "                new_cols[i] = tuple([self.cnts_[keys][out] for out in self.possible_outcomes_])\n",
    "        # print(str(X)[:100])\n",
    "        # print(str(new_cols)[:100])\n",
    "        # print(str(self.fq_cols_[:100]))\n",
    "        new_cols = pd.DataFrame(new_cols, columns=self.fq_cols_)\n",
    "        for c in self.fq_cols_:\n",
    "            new_cols.loc[:,c].fillna(new_cols.loc[:,c].median(), inplace=True)\n",
    "        X = pd.concat((X, new_cols,), axis=1)\n",
    "        if self.drop:\n",
    "            X.drop(self.groupby, axis=1, inplace=True)\n",
    "        return X\n",
    "\n",
    "class ExplicitAge(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X.loc[:, 'age'] = X.loc[:,'date_recorded_year'] - X.loc[:,'construction_year']\n",
    "\n",
    "prepr3 = Pipeline([\n",
    "    ('fillna', HideMissingValues()),\n",
    "    ('date_recorded', SplitDate('date_recorded')),\n",
    "    ('handyfeats', HandyFeatures()),\n",
    "] + [\n",
    "    (catcol + '_fq', OutcomeFrequences2(catcol, drop=True))\n",
    "] + [\n",
    "    ('age', ExplicitAge()),\n",
    "    ('drop', DropGarbage(cols=[\n",
    "        'id', 'recorded_by',\n",
    "        'region', 'funder', 'installer',\n",
    "        'wtp_name'\n",
    "    ]))\n",
    "])\n",
    "\n",
    "y_enc = sklearn.preprocessing.LabelEncoder()\n",
    "y = y_enc.fit_transform(y_train.iloc[:,1])\n",
    "X = prepr3.fit_transform(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_cv, X_te, y_tr, y_cv, y_te = split_train_cv_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!date\n",
    "cbc3 = catboost.CatBoostClassifier(random_seed=SEED,\n",
    "         loss_function='MultiClass',\n",
    "         eval_set=(X_cv, y_cv))\n",
    "cbc3.fit(X_tr,\n",
    "         y_tr,\n",
    "         cat_features=np.where(np.array([dt == object for dt in X.dtypes]))[0],\n",
    "         verbose=True)\n",
    "!date\n",
    "display('score: %s' % cbc3.score(X_te, y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test3 = cbc3.predict(prepr3.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans3 = pd.DataFrame({'status_group': y_enc.inverse_transform(y_test3.astype(int).ravel())},\n",
    "                    index= X_test.iloc[:,0].values)\n",
    "ans3.index.name = 'id'\n",
    "ans3.to_csv('ans3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ans1.csv ans2.csv ans3.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('score on a full train: %s' % cbc3.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepr4 = Pipeline([\n",
    "    ('fillna', HideMissingValues()),\n",
    "    ('date_recorded', SplitDate('date_recorded')),\n",
    "    ('handyfeats', HandyFeatures()),\n",
    "    ('district_fq', OutcomeFrequences2(['district_code'])),\n",
    "    ('basin_fq', OutcomeFrequences2(['basin'])),\n",
    "    ('installer_fq', OutcomeFrequences2(['installer'])),\n",
    "    ('extraction_t_c_fq', OutcomeFrequences2(['extraction_type_class'])),\n",
    "    ('wpt_type_fq', OutcomeFrequences2(['waterpoint_type'])),\n",
    "    ('wpt_name_fq', OutcomeFrequences2(['wtp_name'])),\n",
    "    ('age', ExplicitAge()),\n",
    "    ('drop', DropGarbage(cols=[\n",
    "        'id', 'recorded_by',\n",
    "        'region', 'funder', 'installer',\n",
    "        'wtp_name', 'scheme_management',\n",
    "        'num_private', 'subvillage', \n",
    "        'longtitude', 'latitude',\n",
    "        'date_recorded_day', 'date_recorded_weekday'\n",
    "    ]))\n",
    "])\n",
    "\n",
    "y = y_enc.fit_transform(y_train.iloc[:,1])\n",
    "X = prepr4.fit_transform(X_train, y)\n",
    "X_tr, X_cv, X_te, y_tr, y_cv, y_te = split_train_cv_test(X, y)\n",
    "!date\n",
    "cbc4 = catboost.CatBoostClassifier(random_seed=SEED,\n",
    "         loss_function='MultiClass',\n",
    "         eval_set=(X_cv, y_cv))\n",
    "cat_features = np.where(np.array([(X[c].dtype == object) or ('code' in c) for dt in X.columns.values]))[0]\n",
    "cbc4.fit(X_tr,\n",
    "         y_tr,\n",
    "         cat_features=cat_features,\n",
    "         verbose=True)\n",
    "!date\n",
    "display('score: %s' % cbc4.score(X_te, y_te))\n",
    "y_test4 = cbc4.predict(prepr4.transform(X_test))\n",
    "ans4 = pd.DataFrame({'status_group': y_enc.inverse_transform(y_test4.astype(int).ravel())},\n",
    "                    index= X_test.iloc[:,0].values)\n",
    "ans4.index.name = 'id'\n",
    "ans4.to_csv('ans4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
